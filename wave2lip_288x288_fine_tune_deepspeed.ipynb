{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4416c96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# An sample to finetune wave2lip on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95febd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Update sagemaker python sdk version\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158e94ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sagemaker_default_bucket = sess.default_bucket()\n",
    "\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0c829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## download training script from github\n",
    "!rm -rf ./wav2lip_288x288\n",
    "!git clone https://github.com/whn09/wav2lip_288x288.git\n",
    "!cp ./s5cmd ./wav2lip_288x288/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5a450",
   "metadata": {},
   "source": [
    "## Download pretrained model(expert Discriminator & face detect) and upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e0bed-ee4f-43d5-afbb-c61907353552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ./wav2lip_288x288/face_detection/detection/sfd/ && wget https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
    "!mv ./wav2lip_288x288/face_detection/detection/sfd/s3fd-619a316812.pth ./wav2lip_288x288/face_detection/detection/sfd/s3fd.pth\n",
    "# !cd ./Wav2Lip/models && wget https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588d498",
   "metadata": {},
   "source": [
    "## Prepare docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2057f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04 \n",
    "#From pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime\n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "\n",
    "RUN  apt-get update\n",
    "RUN  echo \"Y\"|apt-get install ffmpeg\n",
    "RUN  pip3 install deepspeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ee553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b0fb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Build image and push to ECR.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53800617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sagemaker-wav2lip-288x288-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d98c7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa7288-4f61-4896-93b7-12fd03055c53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Prepare train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef55e2",
   "metadata": {},
   "source": [
    "use s3 dataset path, which is aligned with data_root of wav2lip \n",
    "should be like:  \n",
    "data_root (mvlrs_v1)  \n",
    "├── main, pretrain (we use only main folder in this work)  \n",
    "|\t├── list of folders  \n",
    "|\t│   ├── five-digit numbered video IDs ending with (.mp4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90becfa3-2ec1-4735-b337-33891f12d1d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://bj.bcebos.com/ai-studio-online/88f38e14dc9f4893bdb3ad6857b810a9e0ed6d63f4f84d7da0b69e165ca4f7a5?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2022-09-04T15%3A27%3A21Z%2F-1%2F%2F2048bfe72ab62c84e2a6622f565ac7cc30830ffdace4607bf847909d1038b5b0&responseContentDisposition=attachment%3B%20filename%3Dmain.zip\n",
    "!./s5cmd sync ./main2/ s3://{sagemaker_default_bucket}/wav2lip_288x288/train_data/main2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7f140-733f-4626-97af-78b3436c8616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 准备filelists/train.txt\n",
    "import os\n",
    "\n",
    "import time\n",
    "from glob import glob\n",
    "import shutil,os\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n",
    "# 去除名字的特殊符号，统一序号视频文件命名\n",
    " \n",
    "# def original_video_name_format():\n",
    "#     base_path = \"../LSR2/main\"\n",
    "#     result = list(glob(\"{}/*\".format(base_path),recursive=False))\n",
    "#     file_num = 0\n",
    "#     result_list = []\n",
    " \n",
    "#     for each in result:\n",
    "#         file_num +=1\n",
    "#         new_position =\"{0}{1}\".format( int(time.time()),file_num)\n",
    "#         result_list.append(new_position)\n",
    "#         shutil.move(each, os.path.join(base_path,new_position+\".mp4\"))\n",
    "#         pass\n",
    "\n",
    "def trained_data_name_format():\n",
    "    base_path = \"../LSR2/lrs2_preprocessed\"\n",
    "    # result = list(glob(\"{}/*\".format(base_path)))\n",
    "    result = os.listdir(base_path)\n",
    "    print(result)\n",
    "    result_list = []\n",
    "    for i,dirpath in enumerate(result):\n",
    "        # shutil.move(dirpath,\"{0}/{1}\".format(base_path,i))\n",
    "        # result_list.append(str(i))\n",
    "        # print('dirpath:', dirpath)\n",
    "        result_list.append(dirpath)\n",
    "    if len(result_list)<14:\n",
    "        test_result=val_result=train_result=result_list\n",
    "    else:\n",
    "        train_result,test_result = train_test_split(result_list,test_size=0.15, random_state=42)\n",
    "        test_result, val_result = train_test_split(test_result, test_size=0.5, random_state=42)\n",
    " \n",
    "    for file_name,dataset in zip((\"train.txt\",\"test.txt\",\"val.txt\"),(train_result,test_result,val_result)):\n",
    "        with open(os.path.join(\"filelists\",file_name),'w',encoding='utf-8') as fi:\n",
    "            for dataset_i in dataset:\n",
    "                # print('dataset_i:', dataset_i)\n",
    "                video_result = os.listdir(os.path.join(base_path, dirpath))\n",
    "                # print('video_result:', video_result)\n",
    "                video_result = [dataset_i+'/'+video for video in video_result]\n",
    "                fi.write(\"\\n\".join(video_result))\n",
    "                fi.write(\"\\n\")\n",
    " \n",
    "    # print(\"\\n\".join(result_list))\n",
    "\n",
    "trained_data_name_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8ac60-b8bd-44b6-9308-f024ea49c040",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### for local data process test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f553a9-582a-43a5-9dd9-6742c390c02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a618b1d-5bf1-492a-92e0-a9043c117da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###data process\n",
    "#!pip install -r ./requirements.txt\n",
    "!cd ./Wav2Lip/ && python preprocess.py --data_root ../main2 --preprocessed_root ../lrs2_preprocessed2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62c4f7-5beb-4c14-be0c-29ed079bbd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./s5cmd sync ./lrs2_preprocessed2/ s3://{sagemaker_default_bucket}/288x288/train_data/lrs2_preprocessed/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d5b8f-188e-4e46-b998-903b462f59cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 开始训练(单机单卡）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cedcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./wav2lip_288x288/train.sh\n",
    "#!/bin/bash\n",
    "\n",
    "chmod +x ./s5cmd\n",
    "./s5cmd sync s3://${sagemaker_default_bucket}/wav2lip_288x288/train_data/main2/* /tmp/main2/\n",
    "pip install -r ./requirements.txt\n",
    "\n",
    "echo \"--------preprocess wav-----------\"\n",
    "python ./preprocess.py --data_root /tmp/main2 --preprocessed_root /tmp/lrs2_preprocessed2/\n",
    "echo \"finished preprocess\"\n",
    "\n",
    "echo \"--------prepare tain list--------\"\n",
    "python ./generate_filelists.py\n",
    "echo \"finished train list prepare\"\n",
    "\n",
    "echo \"--------train the expert discriminator------\"\n",
    "python ./color_syncnet_train.py --data_root /tmp/lrs2_preprocessed2/ --checkpoint_dir /tmp/trained_syncnet/\n",
    "echo \"finished train syncnet\"\n",
    "\n",
    "echo \"--------train wav2lip-----------------------\" \n",
    "python ./hq_wav2lip_train.py --data_root /tmp/lrs2_preprocessed2/ --checkpoint_dir /tmp/trained_wav2lip_288x288/ --syncnet_checkpoint_path /tmp/trained_syncnet/checkpoint_step000000001.pth\n",
    "echo \"finished wav2lip\"\n",
    "\n",
    "./s5cmd sync /tmp/trained_wav2lip_288x288/ s3://${sagemaker_default_bucket}/models/wav2lip_288x288/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "###inference\n",
    "echo \"begin inference\"\n",
    "./s5cmd sync  s3://${sagemaker_default_bucket}/wav2lip/inference/face_video/* /tmp/face_video/\n",
    "./s5cmd sync  s3://${sagemaker_default_bucket}/wav2lip/inference/audio/* /tmp/audio/\n",
    "python ./inference.py --checkpoint_path /tmp/trained_wav2lip_288x288/checkpoint_step000000001.pth  --face /tmp/face_video/VID20230623143819.mp4 --audio /tmp/audio/测试wav2lip.mp3\n",
    "./s5cmd sync ./results/result_voice.mp4  s3://${sagemaker_default_bucket}/models/wav2lip_288x288/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517889b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, repo_name)\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad795754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set train_data_path to your training dataset path in s3\n",
    "train_data_path = f's3://{sagemaker_default_bucket}/wav2lip_288x288/train_data/'.format(sagemaker_default_bucket)\n",
    "\n",
    "\n",
    "inputs = {'data_root': train_data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab36100",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "environment = {\n",
    "              'sagemaker_default_bucket': sagemaker_default_bucket # The bucket to store pretrained model and fine-tune model\n",
    "}\n",
    "\n",
    "base_job_name = 'wav2lip-288x288-demo'         \n",
    "\n",
    "instance_type = 'ml.g5.8xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='train.sh',\n",
    "                      source_dir='./wav2lip_288x288/',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600,\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa5918-57f2-455e-98f3-ecb59c47135f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://${sagemaker_default_bucket}/models/wav2lip_288x288/results/result_voice.mp4 ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d6593-90ad-4409-ae65-17e618a6c91c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### deepspeed （单机多卡）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420efdac-3199-40e2-a81a-1c727ca7c868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sagemaker-wav2lip-288x288-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0e5783-8d3e-4964-bcdd-bc3b96fe8c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'687912291502.dkr.ecr.us-west-2.amazonaws.com/sagemaker-wav2lip-288x288-demo:latest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, repo_name)\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f960df78-8a29-4991-955d-5c04c82dd1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## set train_data_path to your training dataset path in s3\n",
    "train_data_path = f's3://{sagemaker_default_bucket}/wav2lip_288x288/train_data/'.format(sagemaker_default_bucket)\n",
    "inputs = {'data_root': train_data_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21eb734a-d22b-47a1-886a-c8a592b0a53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./wav2lip_288x288/color_syncnet_dist_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./wav2lip_288x288/color_syncnet_dist_train.py\n",
    "from os.path import dirname, join, basename, isfile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from models import SyncNet_color as SyncNet\n",
    "import audio\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils import data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "import deepspeed\n",
    "\n",
    "import os, random, cv2, argparse\n",
    "from hparams import hparams, get_image_list\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Code to train the expert lip-sync discriminator')\n",
    "\n",
    "parser.add_argument(\"--data_root\", help=\"Root folder of the preprocessed LRS2 dataset\", required=True)\n",
    "\n",
    "parser.add_argument('--checkpoint_dir', help='Save checkpoints to this directory', required=True, type=str)\n",
    "parser.add_argument('--checkpoint_path', help='Resumed from this checkpoint', default=None, type=str)\n",
    "## Include DeepSpeed configuration arguments\n",
    "parser.add_argument('--local_rank', type=int, default=-1, help='local rank passed from distributed launcher')\n",
    "parser = deepspeed.add_config_arguments(parser)\n",
    "args = parser.parse_args()\n",
    "\n",
    "global_step = 0\n",
    "global_epoch = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('use_cuda: {}'.format(use_cuda))\n",
    "\n",
    "syncnet_T = 5\n",
    "syncnet_mel_step_size = 16\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, split):\n",
    "        self.all_videos = get_image_list(args.data_root, split)\n",
    "\n",
    "    def get_frame_id(self, frame):\n",
    "        return int(basename(frame).split('.')[0])\n",
    "\n",
    "    def get_window(self, start_frame):\n",
    "        start_id = self.get_frame_id(start_frame)\n",
    "        vidname = dirname(start_frame)\n",
    "\n",
    "        window_fnames = []\n",
    "        for frame_id in range(start_id, start_id + syncnet_T):\n",
    "            frame = join(vidname, '{}.jpg'.format(frame_id))  # '{}.jpg' '{}.png'\n",
    "            if not isfile(frame):\n",
    "                return None\n",
    "            window_fnames.append(frame)\n",
    "        return window_fnames\n",
    "\n",
    "    def crop_audio_window(self, spec, start_frame):\n",
    "        # num_frames = (T x hop_size * fps) / sample_rate\n",
    "        start_frame_num = self.get_frame_id(start_frame)\n",
    "        start_idx = int(80. * (start_frame_num / float(hparams.fps)))\n",
    "\n",
    "        end_idx = start_idx + syncnet_mel_step_size\n",
    "\n",
    "        return spec[start_idx : end_idx, :]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while 1:\n",
    "            idx = random.randint(0, len(self.all_videos) - 1)\n",
    "            vidname = self.all_videos[idx]\n",
    "\n",
    "            img_names = list(glob(join(vidname, '*.jpg')))  # '*.jpg' '*.png'\n",
    "            # print('vidname:', vidname, 'img_names:', len(img_names))\n",
    "            if len(img_names) <= 3 * syncnet_T:\n",
    "                # print('CONTINUE: len(img_names) <= 3 * syncnet_T')\n",
    "                continue\n",
    "            img_name = random.choice(img_names)\n",
    "            wrong_img_name = random.choice(img_names)\n",
    "            while wrong_img_name == img_name:\n",
    "                wrong_img_name = random.choice(img_names)\n",
    "\n",
    "            if random.choice([True, False]):\n",
    "                y = torch.ones(1).float()\n",
    "                chosen = img_name\n",
    "            else:\n",
    "                y = torch.zeros(1).float()\n",
    "                chosen = wrong_img_name\n",
    "\n",
    "            window_fnames = self.get_window(chosen)\n",
    "            if window_fnames is None:\n",
    "                # print('CONTINUE: window_fnames is None. chosen:', chosen)\n",
    "                continue\n",
    "\n",
    "            window = []\n",
    "            all_read = True\n",
    "            for fname in window_fnames:\n",
    "                img = cv2.imread(fname)\n",
    "                if img is None:\n",
    "                    all_read = False\n",
    "                    break\n",
    "                try:\n",
    "                    img = cv2.resize(img, (hparams.img_size, hparams.img_size))\n",
    "                except Exception as e:\n",
    "                    all_read = False\n",
    "                    break\n",
    "\n",
    "                window.append(img)\n",
    "\n",
    "            if not all_read: continue\n",
    "\n",
    "            try:\n",
    "                wavpath = join(vidname, \"audio.wav\")  # \"audio.wav\" \"../audio.wav\"\n",
    "                wav = audio.load_wav(wavpath, hparams.sample_rate)\n",
    "\n",
    "                orig_mel = audio.melspectrogram(wav).T\n",
    "            except Exception as e:\n",
    "                # print('CONTINUE Exception:', e, ', wavpath:', wavpath, ', wav:', wav)\n",
    "                continue\n",
    "\n",
    "            mel = self.crop_audio_window(orig_mel.copy(), img_name)\n",
    "\n",
    "            if (mel.shape[0] != syncnet_mel_step_size):\n",
    "                # print('CONTINUE: mel.shape[0] != syncnet_mel_step_size')\n",
    "                continue\n",
    "\n",
    "            # H x W x 3 * T\n",
    "            x = np.concatenate(window, axis=2) / 255.\n",
    "            x = x.transpose(2, 0, 1)\n",
    "            x = x[:, x.shape[1]//2:]\n",
    "\n",
    "            x = torch.FloatTensor(x)\n",
    "            mel = torch.FloatTensor(mel.T).unsqueeze(0)\n",
    "            \n",
    "            # print('x, mel, y:', x, mel, y)\n",
    "\n",
    "            return x, mel, y\n",
    "\n",
    "logloss = nn.BCELoss()\n",
    "def cosine_loss(a, v, y):\n",
    "    # print('a:', a.shape, ', v:', v.shape, ', y:', y.shape)\n",
    "    # print('a:', torch.isnan(a).any(), ', v:', torch.isnan(v).any(), ', y:', torch.isnan(y).any())\n",
    "    # print('a:', torch.isinf(a).any(), ', v:', torch.isinf(v).any(), ', y:', torch.isinf(y).any())\n",
    "    d = nn.functional.cosine_similarity(a, v)\n",
    "    # print('d:', d.shape, torch.isnan(d).any(), d)\n",
    "    # print('y:', y.shape, torch.isnan(y).any(), y)\n",
    "    d = torch.clamp(d, min=0.0)  # TODO Pytorch.clamp：将小于0的元素修改为0，截断元素的取值空间\n",
    "    loss = logloss(d.unsqueeze(1), y)\n",
    "    # print('loss:', loss)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(device, model_engine, train_data_loader, test_data_loader, optimizer_deepspeed,\n",
    "          checkpoint_dir=None, checkpoint_interval=None, nepochs=None):\n",
    "\n",
    "    global global_step, global_epoch\n",
    "    resumed_step = global_step\n",
    "    \n",
    "    while global_epoch < nepochs:\n",
    "        running_loss = 0.\n",
    "        prog_bar = tqdm(enumerate(train_data_loader))\n",
    "        for step, (x, mel, y) in prog_bar:\n",
    "        # for step, (x, mel, y) in enumerate(train_data_loader):\n",
    "            model_engine.train()\n",
    "            #optimizer.zero_grad()\n",
    "\n",
    "            # Transform data to CUDA device\n",
    "            # print('x:', x.shape)\n",
    "            x = x.to(device)\n",
    "\n",
    "            mel = mel.to(device)\n",
    "\n",
    "            a, v = model_engine(mel, x)\n",
    "            y = y.to(device)\n",
    "\n",
    "            loss = cosine_loss(a, v, y)\n",
    "            model_engine.backward(loss)\n",
    "            model_engine.step()\n",
    "\n",
    "            global_step += 1\n",
    "            cur_session_steps = global_step - resumed_step\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if global_step % checkpoint_interval == 0:\n",
    "                save_checkpoint(\n",
    "                    model_engine, optimizer_deepspeed, global_step, checkpoint_dir, global_epoch)\n",
    "\n",
    "            #if global_step % hparams.syncnet_eval_interval == 0:\n",
    "            #    with torch.no_grad():\n",
    "            #        eval_model(test_data_loader, global_step, device, model, checkpoint_dir)\n",
    "\n",
    "            prog_bar.set_description('Loss: {}'.format(running_loss / (step + 1)))\n",
    "            # print('Loss: {}'.format(running_loss / (step + 1)))\n",
    "\n",
    "        global_epoch += 1\n",
    "\n",
    "def eval_model(test_data_loader, global_step, device, model, checkpoint_dir):\n",
    "    eval_steps = 1400\n",
    "    print('Evaluating for {} steps'.format(eval_steps))\n",
    "    losses = []\n",
    "    while 1:\n",
    "        for step, (x, mel, y) in enumerate(test_data_loader):\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            # Transform data to CUDA device\n",
    "            x = x.to(device)\n",
    "\n",
    "            mel = mel.to(device)\n",
    "\n",
    "            a, v = model(mel, x)\n",
    "            y = y.to(device)\n",
    "\n",
    "            loss = cosine_loss(a, v, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if step > eval_steps: break\n",
    "\n",
    "        averaged_loss = sum(losses) / len(losses)\n",
    "        print(averaged_loss)\n",
    "\n",
    "        return\n",
    "\n",
    "def save_checkpoint(model_engine, optimizer, step, checkpoint_dir, epoch):\n",
    "    # 获取当前时间戳\n",
    "    timestamp = int(time.time())\n",
    "    model_engine.save_checkpoint(checkpoint_dir)\n",
    "    #torch_model = model_engine.module\n",
    "    #output_model_path = checkpoint_dir+str(timestamp)+\"_\"+str(step)+\"_trained_syncnet.pth\"\n",
    "    #torch.save(torch_model.state_dict(), output_model_path)\n",
    "    print(\"Saved checkpoint:\", checkpoint_dir)\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if use_cuda:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path,\n",
    "                                map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, reset_optimizer=False):\n",
    "    global global_step\n",
    "    global global_epoch\n",
    "\n",
    "    print(\"Load checkpoint from: {}\".format(path))\n",
    "    checkpoint = _load(path)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    if not reset_optimizer:\n",
    "        optimizer_state = checkpoint[\"optimizer\"]\n",
    "        if optimizer_state is not None:\n",
    "            print(\"Load optimizer state from {}\".format(path))\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    global_step = checkpoint[\"global_step\"]\n",
    "    global_epoch = checkpoint[\"global_epoch\"]\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = args.checkpoint_dir\n",
    "    checkpoint_path = args.checkpoint_path\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "\n",
    "    # Dataset and Dataloader setup\n",
    "    train_dataset = Dataset('train')\n",
    "    test_dataset = Dataset('val')\n",
    "    print('train_dataset:', len(train_dataset))\n",
    "    print('test_dataset:', len(test_dataset))\n",
    "\n",
    "    train_data_loader = data_utils.DataLoader(\n",
    "        train_dataset, batch_size=hparams.syncnet_batch_size, shuffle=True,\n",
    "        num_workers=hparams.num_workers)\n",
    "\n",
    "    test_data_loader = data_utils.DataLoader(\n",
    "        test_dataset, batch_size=hparams.syncnet_batch_size,\n",
    "        num_workers=8)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # Model\n",
    "    model = SyncNet().to(device)\n",
    "    print('total trainable params {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],\n",
    "                           lr=hparams.syncnet_lr)\n",
    "\n",
    "    ###deepspeed 改造#################\n",
    "    model_engine, optimizer_deepspeed, _, _ = deepspeed.initialize(args=args,model=model,optimizer=optimizer)\n",
    "    \n",
    "    if checkpoint_path is not None:\n",
    "        load_checkpoint(checkpoint_path, model, optimizer, reset_optimizer=False)\n",
    "\n",
    "    train(device, model_engine, train_data_loader, test_data_loader, optimizer_deepspeed,\n",
    "          checkpoint_dir=checkpoint_dir,\n",
    "          checkpoint_interval=hparams.syncnet_checkpoint_interval,\n",
    "          nepochs=hparams.nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cea58ef0-542a-4a5d-82fa-83c5ed0b3c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./wav2lip_288x288/hq_wav2lip_train_deepspeed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./wav2lip_288x288/hq_wav2lip_train_deepspeed.py\n",
    "from os.path import dirname, join, basename, isfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SyncNet_color as SyncNet\n",
    "from models import Wav2Lip, Wav2Lip_disc_qual\n",
    "import audio\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils import data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import os, random, cv2, argparse\n",
    "from hparams import hparams, get_image_list\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Code to train the Wav2Lip model WITH the visual quality discriminator')\n",
    "\n",
    "parser.add_argument(\"--data_root\", help=\"Root folder of the preprocessed LRS2 dataset\", required=True, type=str)\n",
    "\n",
    "parser.add_argument('--checkpoint_dir', help='Save checkpoints to this directory', required=True, type=str)\n",
    "parser.add_argument('--syncnet_checkpoint_path', help='Load the pre-trained Expert discriminator', required=True, type=str)\n",
    "\n",
    "parser.add_argument('--checkpoint_path', help='Resume generator from this checkpoint', default=None, type=str)\n",
    "parser.add_argument('--disc_checkpoint_path', help='Resume quality disc from this checkpoint', default=None, type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "global_epoch = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('use_cuda: {}'.format(use_cuda))\n",
    "\n",
    "syncnet_T = 5\n",
    "syncnet_mel_step_size = 16\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, split):\n",
    "        self.all_videos = get_image_list(args.data_root, split)\n",
    "\n",
    "    def get_frame_id(self, frame):\n",
    "        return int(basename(frame).split('.')[0])\n",
    "\n",
    "    def get_window(self, start_frame):\n",
    "        start_id = self.get_frame_id(start_frame)\n",
    "        vidname = dirname(start_frame)\n",
    "\n",
    "        window_fnames = []\n",
    "        for frame_id in range(start_id, start_id + syncnet_T):\n",
    "            frame = join(vidname, '{}.jpg'.format(frame_id))\n",
    "            if not isfile(frame):\n",
    "                return None\n",
    "            window_fnames.append(frame)\n",
    "        return window_fnames\n",
    "\n",
    "    def read_window(self, window_fnames):\n",
    "        if window_fnames is None: return None\n",
    "        window = []\n",
    "        for fname in window_fnames:\n",
    "            img = cv2.imread(fname)\n",
    "            if img is None:\n",
    "                return None\n",
    "            try:\n",
    "                img = cv2.resize(img, (hparams.img_size, hparams.img_size))\n",
    "            except Exception as e:\n",
    "                return None\n",
    "\n",
    "            window.append(img)\n",
    "\n",
    "        return window\n",
    "\n",
    "    def crop_audio_window(self, spec, start_frame):\n",
    "        if type(start_frame) == int:\n",
    "            start_frame_num = start_frame\n",
    "        else:\n",
    "            start_frame_num = self.get_frame_id(start_frame)\n",
    "        start_idx = int(80. * (start_frame_num / float(hparams.fps)))\n",
    "        \n",
    "        end_idx = start_idx + syncnet_mel_step_size\n",
    "\n",
    "        return spec[start_idx : end_idx, :]\n",
    "\n",
    "    def get_segmented_mels(self, spec, start_frame):\n",
    "        mels = []\n",
    "        assert syncnet_T == 5\n",
    "        start_frame_num = self.get_frame_id(start_frame) + 1 # 0-indexing ---> 1-indexing\n",
    "        if start_frame_num - 2 < 0: return None\n",
    "        for i in range(start_frame_num, start_frame_num + syncnet_T):\n",
    "            m = self.crop_audio_window(spec, i - 2)\n",
    "            if m.shape[0] != syncnet_mel_step_size:\n",
    "                return None\n",
    "            mels.append(m.T)\n",
    "\n",
    "        mels = np.asarray(mels)\n",
    "\n",
    "        return mels\n",
    "\n",
    "    def prepare_window(self, window):\n",
    "        # 3 x T x H x W\n",
    "        x = np.asarray(window) / 255.\n",
    "        x = np.transpose(x, (3, 0, 1, 2))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while 1:\n",
    "            idx = random.randint(0, len(self.all_videos) - 1)\n",
    "            vidname = self.all_videos[idx]\n",
    "            img_names = list(glob(join(vidname, '*.jpg')))\n",
    "            if len(img_names) <= 3 * syncnet_T:\n",
    "                continue\n",
    "            \n",
    "            img_name = random.choice(img_names)\n",
    "            wrong_img_name = random.choice(img_names)\n",
    "            while wrong_img_name == img_name:\n",
    "                wrong_img_name = random.choice(img_names)\n",
    "\n",
    "            window_fnames = self.get_window(img_name)\n",
    "            wrong_window_fnames = self.get_window(wrong_img_name)\n",
    "            if window_fnames is None or wrong_window_fnames is None:\n",
    "                continue\n",
    "\n",
    "            window = self.read_window(window_fnames)\n",
    "            if window is None:\n",
    "                continue\n",
    "\n",
    "            wrong_window = self.read_window(wrong_window_fnames)\n",
    "            if wrong_window is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                wavpath = join(vidname, \"audio.wav\")\n",
    "                wav = audio.load_wav(wavpath, hparams.sample_rate)\n",
    "\n",
    "                orig_mel = audio.melspectrogram(wav).T\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            mel = self.crop_audio_window(orig_mel.copy(), img_name)\n",
    "            \n",
    "            if (mel.shape[0] != syncnet_mel_step_size):\n",
    "                continue\n",
    "\n",
    "            indiv_mels = self.get_segmented_mels(orig_mel.copy(), img_name)\n",
    "            if indiv_mels is None: continue\n",
    "\n",
    "            window = self.prepare_window(window)\n",
    "            y = window.copy()\n",
    "            window[:, :, window.shape[2]//2:] = 0.\n",
    "\n",
    "            wrong_window = self.prepare_window(wrong_window)\n",
    "            x = np.concatenate([window, wrong_window], axis=0)\n",
    "\n",
    "            x = torch.FloatTensor(x)\n",
    "            mel = torch.FloatTensor(mel.T).unsqueeze(0)\n",
    "            indiv_mels = torch.FloatTensor(indiv_mels).unsqueeze(1)\n",
    "            y = torch.FloatTensor(y)\n",
    "            return x, indiv_mels, mel, y\n",
    "\n",
    "def save_sample_images(x, g, gt, global_step, checkpoint_dir):\n",
    "    x = (x.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n",
    "    g = (g.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n",
    "    gt = (gt.detach().cpu().numpy().transpose(0, 2, 3, 4, 1) * 255.).astype(np.uint8)\n",
    "\n",
    "    refs, inps = x[..., 3:], x[..., :3]\n",
    "    folder = join(checkpoint_dir, \"samples_step{:09d}\".format(global_step))\n",
    "    if not os.path.exists(folder): os.mkdir(folder)\n",
    "    collage = np.concatenate((refs, inps, g, gt), axis=-2)\n",
    "    for batch_idx, c in enumerate(collage):\n",
    "        for t in range(len(c)):\n",
    "            cv2.imwrite('{}/{}_{}.jpg'.format(folder, batch_idx, t), c[t])\n",
    "\n",
    "logloss = nn.BCELoss()\n",
    "def cosine_loss(a, v, y):\n",
    "    d = nn.functional.cosine_similarity(a, v)\n",
    "    loss = logloss(d.unsqueeze(1), y)\n",
    "\n",
    "    return loss\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "syncnet = SyncNet().to(device)\n",
    "for p in syncnet.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "recon_loss = nn.L1Loss()\n",
    "def get_sync_loss(mel, g):\n",
    "    g = g[:, :, :, g.size(3)//2:]\n",
    "    g = torch.cat([g[:, :, i] for i in range(syncnet_T)], dim=1)\n",
    "    # B, 3 * T, H//2, W\n",
    "    a, v = syncnet(mel, g)\n",
    "    y = torch.ones(g.size(0), 1).float().to(device)\n",
    "    return cosine_loss(a, v, y)\n",
    "\n",
    "def train(device, model, disc, train_data_loader, test_data_loader, optimizer, disc_optimizer,\n",
    "          checkpoint_dir=None, checkpoint_interval=None, nepochs=None):\n",
    "    global global_step, global_epoch\n",
    "    resumed_step = global_step\n",
    "\n",
    "    while global_epoch < nepochs:\n",
    "        print('Starting Epoch: {}'.format(global_epoch))\n",
    "        running_sync_loss, running_l1_loss, disc_loss, running_perceptual_loss = 0., 0., 0., 0.\n",
    "        running_disc_real_loss, running_disc_fake_loss = 0., 0.\n",
    "        prog_bar = tqdm(enumerate(train_data_loader))\n",
    "        for step, (x, indiv_mels, mel, gt) in prog_bar:\n",
    "            disc.train()\n",
    "            model.train()\n",
    "\n",
    "            x = x.to(device)\n",
    "            mel = mel.to(device)\n",
    "            indiv_mels = indiv_mels.to(device)\n",
    "            gt = gt.to(device)\n",
    "\n",
    "            ### Train generator now. Remove ALL grads. \n",
    "            optimizer.zero_grad()\n",
    "            disc_optimizer.zero_grad()\n",
    "\n",
    "            g = model(indiv_mels, x)\n",
    "\n",
    "            if hparams.syncnet_wt > 0.:\n",
    "                sync_loss = get_sync_loss(mel, g)\n",
    "            else:\n",
    "                sync_loss = 0.\n",
    "\n",
    "            if hparams.disc_wt > 0.:\n",
    "                perceptual_loss = disc.perceptual_forward(g)\n",
    "            else:\n",
    "                perceptual_loss = 0.\n",
    "\n",
    "            l1loss = recon_loss(g, gt)\n",
    "\n",
    "            loss = hparams.syncnet_wt * sync_loss + hparams.disc_wt * perceptual_loss + \\\n",
    "                                    (1. - hparams.syncnet_wt - hparams.disc_wt) * l1loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### Remove all gradients before Training disc\n",
    "            disc_optimizer.zero_grad()\n",
    "\n",
    "            pred = disc(gt)\n",
    "            disc_real_loss = F.binary_cross_entropy(pred, torch.ones((len(pred), 1)).to(device))\n",
    "            disc_real_loss.backward()\n",
    "\n",
    "            pred = disc(g.detach())\n",
    "            disc_fake_loss = F.binary_cross_entropy(pred, torch.zeros((len(pred), 1)).to(device))\n",
    "            disc_fake_loss.backward()\n",
    "\n",
    "            disc_optimizer.step()\n",
    "\n",
    "            running_disc_real_loss += disc_real_loss.item()\n",
    "            running_disc_fake_loss += disc_fake_loss.item()\n",
    "\n",
    "            if global_step % checkpoint_interval == 0:\n",
    "                save_sample_images(x, g, gt, global_step, checkpoint_dir)\n",
    "\n",
    "            # Logs\n",
    "            global_step += 1\n",
    "            cur_session_steps = global_step - resumed_step\n",
    "\n",
    "            running_l1_loss += l1loss.item()\n",
    "            if hparams.syncnet_wt > 0.:\n",
    "                running_sync_loss += sync_loss.item()\n",
    "            else:\n",
    "                running_sync_loss += 0.\n",
    "\n",
    "            if hparams.disc_wt > 0.:\n",
    "                running_perceptual_loss += perceptual_loss.item()\n",
    "            else:\n",
    "                running_perceptual_loss += 0.\n",
    "\n",
    "            if global_step==1 or global_step % checkpoint_interval == 0:\n",
    "                save_checkpoint(\n",
    "                    model, optimizer, global_step, checkpoint_dir, global_epoch)\n",
    "                save_checkpoint(disc, disc_optimizer, global_step, checkpoint_dir, global_epoch, prefix='disc_')\n",
    "\n",
    "\n",
    "            #if global_step % hparams.eval_interval == 0:\n",
    "            #    with torch.no_grad():\n",
    "            #        average_sync_loss = eval_model(test_data_loader, global_step, device, model, disc)\n",
    "\n",
    "            #        if average_sync_loss < .75:\n",
    "            #            hparams.set_hparam('syncnet_wt', 0.03)\n",
    "\n",
    "            prog_bar.set_description('L1: {}, Sync: {}, Percep: {} | Fake: {}, Real: {}'.format(running_l1_loss / (step + 1),\n",
    "                                                                                        running_sync_loss / (step + 1),\n",
    "                                                                                        running_perceptual_loss / (step + 1),\n",
    "                                                                                        running_disc_fake_loss / (step + 1),\n",
    "                                                                                        running_disc_real_loss / (step + 1)))\n",
    "\n",
    "        global_epoch += 1\n",
    "\n",
    "def eval_model(test_data_loader, global_step, device, model, disc):\n",
    "    eval_steps = 300\n",
    "    print('Evaluating for {} steps'.format(eval_steps))\n",
    "    running_sync_loss, running_l1_loss, running_disc_real_loss, running_disc_fake_loss, running_perceptual_loss = [], [], [], [], []\n",
    "    while 1:\n",
    "        for step, (x, indiv_mels, mel, gt) in enumerate((test_data_loader)):\n",
    "            model.eval()\n",
    "            disc.eval()\n",
    "\n",
    "            x = x.to(device)\n",
    "            mel = mel.to(device)\n",
    "            indiv_mels = indiv_mels.to(device)\n",
    "            gt = gt.to(device)\n",
    "\n",
    "            pred = disc(gt)\n",
    "            disc_real_loss = F.binary_cross_entropy(pred, torch.ones((len(pred), 1)).to(device))\n",
    "\n",
    "            g = model(indiv_mels, x)\n",
    "            pred = disc(g)\n",
    "            disc_fake_loss = F.binary_cross_entropy(pred, torch.zeros((len(pred), 1)).to(device))\n",
    "\n",
    "            running_disc_real_loss.append(disc_real_loss.item())\n",
    "            running_disc_fake_loss.append(disc_fake_loss.item())\n",
    "\n",
    "            sync_loss = get_sync_loss(mel, g)\n",
    "            \n",
    "            if hparams.disc_wt > 0.:\n",
    "                perceptual_loss = disc.perceptual_forward(g)\n",
    "            else:\n",
    "                perceptual_loss = 0.\n",
    "\n",
    "            l1loss = recon_loss(g, gt)\n",
    "\n",
    "            loss = hparams.syncnet_wt * sync_loss + hparams.disc_wt * perceptual_loss + \\\n",
    "                                    (1. - hparams.syncnet_wt - hparams.disc_wt) * l1loss\n",
    "\n",
    "            running_l1_loss.append(l1loss.item())\n",
    "            running_sync_loss.append(sync_loss.item())\n",
    "            \n",
    "            if hparams.disc_wt > 0.:\n",
    "                running_perceptual_loss.append(perceptual_loss.item())\n",
    "            else:\n",
    "                running_perceptual_loss.append(0.)\n",
    "\n",
    "            if step > eval_steps: break\n",
    "\n",
    "        print('L1: {}, Sync: {}, Percep: {} | Fake: {}, Real: {}'.format(sum(running_l1_loss) / len(running_l1_loss),\n",
    "                                                            sum(running_sync_loss) / len(running_sync_loss),\n",
    "                                                            sum(running_perceptual_loss) / len(running_perceptual_loss),\n",
    "                                                            sum(running_disc_fake_loss) / len(running_disc_fake_loss),\n",
    "                                                             sum(running_disc_real_loss) / len(running_disc_real_loss)))\n",
    "        return sum(running_sync_loss) / len(running_sync_loss)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, step, checkpoint_dir, epoch, prefix=''):\n",
    "    checkpoint_path = join(\n",
    "        checkpoint_dir, \"{}checkpoint_step{:09d}.pth\".format(prefix, global_step))\n",
    "    optimizer_state = optimizer.state_dict() if hparams.save_optimizer_state else None\n",
    "    torch.save({\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer_state,\n",
    "        \"global_step\": step,\n",
    "        \"global_epoch\": epoch,\n",
    "    }, checkpoint_path)\n",
    "    print(\"Saved checkpoint:\", checkpoint_path)\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if use_cuda:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path,\n",
    "                                map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, reset_optimizer=False, overwrite_global_states=True):\n",
    "    global global_step\n",
    "    global global_epoch\n",
    "\n",
    "    print(\"Load checkpoint from: {}\".format(path))\n",
    "    checkpoint = _load(path)\n",
    "    s = checkpoint[\"state_dict\"]\n",
    "    new_s = {}\n",
    "    for k, v in s.items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    if not reset_optimizer:\n",
    "        optimizer_state = checkpoint[\"optimizer\"]\n",
    "        if optimizer_state is not None:\n",
    "            print(\"Load optimizer state from {}\".format(path))\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    if overwrite_global_states:\n",
    "        global_step = checkpoint[\"global_step\"]\n",
    "        global_epoch = checkpoint[\"global_epoch\"]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_checkpoint_syncnet(path, model):\n",
    "    global global_step\n",
    "    global global_epoch\n",
    "\n",
    "    print(\"Load checkpoint from: {}\".format(path))\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"module\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    checkpoint_dir = args.checkpoint_dir\n",
    "\n",
    "    # Dataset and Dataloader setup\n",
    "    train_dataset = Dataset('train')\n",
    "    test_dataset = Dataset('val')\n",
    "\n",
    "    train_data_loader = data_utils.DataLoader(\n",
    "        train_dataset, batch_size=hparams.batch_size, shuffle=True,\n",
    "        num_workers=hparams.num_workers)\n",
    "\n",
    "    test_data_loader = data_utils.DataLoader(\n",
    "        test_dataset, batch_size=hparams.batch_size,\n",
    "        num_workers=4)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "     # Model\n",
    "    model = Wav2Lip().to(device)\n",
    "    disc = Wav2Lip_disc_qual().to(device)\n",
    "\n",
    "    print('total trainable params {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "    print('total DISC trainable params {}'.format(sum(p.numel() for p in disc.parameters() if p.requires_grad)))\n",
    "\n",
    "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],\n",
    "                           lr=hparams.initial_learning_rate, betas=(0.5, 0.999))\n",
    "    disc_optimizer = optim.Adam([p for p in disc.parameters() if p.requires_grad],\n",
    "                           lr=hparams.disc_initial_learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    if args.checkpoint_path is not None:\n",
    "        load_checkpoint(args.checkpoint_path, model, optimizer, reset_optimizer=False)\n",
    "\n",
    "    if args.disc_checkpoint_path is not None:\n",
    "        load_checkpoint(args.disc_checkpoint_path, disc, disc_optimizer, \n",
    "                                reset_optimizer=False, overwrite_global_states=False)\n",
    "        \n",
    "    load_checkpoint_syncnet(args.syncnet_checkpoint_path, syncnet)\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "\n",
    "    # Train!\n",
    "    train(device, model, disc, train_data_loader, test_data_loader, optimizer, disc_optimizer,\n",
    "              checkpoint_dir=checkpoint_dir,\n",
    "              checkpoint_interval=hparams.checkpoint_interval,\n",
    "              nepochs=hparams.nepochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21b9cfe0-ad7c-4fe7-8e81-3a0389d2cc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./wav2lip_288x288/ds_config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./wav2lip_288x288/ds_config.json\n",
    "{\n",
    "  \"fp16\": {\n",
    "    \"enabled\": false,\n",
    "    \"auto_cast\": true,\n",
    "    \"loss_scale\": 0,\n",
    "    \"initial_scale_power\": 16,\n",
    "    \"loss_scale_window\": 1000,\n",
    "    \"hysteresis\": 2,\n",
    "    \"min_loss_scale\": 1\n",
    "  },\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"Adam\",\n",
    "    \"params\": {\n",
    "      \"lr\": 0.001,\n",
    "      \"betas\": [\n",
    "        0.8,\n",
    "        0.999\n",
    "      ],\n",
    "      \"eps\": 1e-8,\n",
    "      \"weight_decay\": 3e-7\n",
    "    }\n",
    "  },\n",
    "  \"scheduler\": {\n",
    "      \"type\": \"WarmupLR\",\n",
    "      \"params\": {\n",
    "          \"warmup_min_lr\": 0,\n",
    "          \"warmup_max_lr\": 0.001,\n",
    "          \"warmup_num_steps\": 1000\n",
    "      }\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "      \"stage\": 0\n",
    "  },\n",
    "  \"gradient_accumulation_steps\": 4,\n",
    "  \"gradient_clipping\": 0.0,\n",
    "  \"steps_per_print\": 2000,\n",
    "  \"train_batch_size\": 64,\n",
    "  \"train_micro_batch_size_per_gpu\": 2,\n",
    "  \"wall_clock_breakdown\": false\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3436f11c-46b2-4586-8fec-bed0e7b37d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./wav2lip_288x288/train-distribute.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./wav2lip_288x288/train-distribute.sh\n",
    "#!/bin/bash\n",
    "\n",
    "chmod +x ./s5cmd\n",
    "./s5cmd sync s3://${MODEL_S3_BUCKET}/wav2lip_288x288/train_data/main2/* /tmp/main2/\n",
    "pip install -r ./requirements.txt\n",
    "\n",
    "echo \"--------preprocess wav-----------\"\n",
    "python ./preprocess.py --data_root /tmp/main2 --preprocessed_root /tmp/lrs2_preprocessed2/\n",
    "echo \"finished preprocess\"\n",
    "\n",
    "echo \"--------prepare tain list--------\"\n",
    "python ./generate_filelists.py\n",
    "echo \"finished train list prepare\"\n",
    "\n",
    "echo \"--------train the expert discriminator------\"\n",
    "deepspeed --num_gpus=8 ./color_syncnet_dist_train.py \\\n",
    "          --data_root /tmp/lrs2_preprocessed2/ \\\n",
    "          --checkpoint_dir /tmp/trained_syncnet/  \\\n",
    "          --deepspeed --deepspeed_config ds_config.json\n",
    "echo \"finished train syncnet\"\n",
    "\n",
    "trained_syncnet_model_file=$(find /tmp/trained_syncnet/ -name  \"*.pt\" -print)\n",
    "trained_syncnet_model_file=$(echo $trained_syncnet_model_file|cut -d' ' -f1)\n",
    "echo \"trained_syncnet_model_file: \"${trained_syncnet_model_file}\n",
    "    \n",
    "echo \"--------train wav2lip-----------------------\" \n",
    "python ./hq_wav2lip_train_deepspeed.py --data_root /tmp/lrs2_preprocessed2/ --checkpoint_dir /tmp/trained_wav2lip_288x288/ --syncnet_checkpoint_path $trained_syncnet_model_file\n",
    "#python ./hq_wav2lip_train.py --data_root /tmp/lrs2_preprocessed2/ --checkpoint_dir /tmp/trained_wav2lip_288x288/ --syncnet_checkpoint_path /tmp/trained_syncnet/10/global_step2/mp_rank_00_model_states.pt\n",
    "          \n",
    "echo \"finished wav2lip\"\n",
    "\n",
    "./s5cmd sync /tmp/trained_wav2lip_288x288/ s3://$MODEL_S3_BUCKET/wav2lip_288x288/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "###inference\n",
    "#echo \"begin inference\"\n",
    "#./s5cmd sync  s3://${sagemaker_default_bucket}/wav2lip/inference/face_video/* /tmp/face_video/\n",
    "#./s5cmd sync  s3://${sagemaker_default_bucket}/wav2lip/inference/audio/* /tmp/audio/\n",
    "#python ./inference.py --checkpoint_path /tmp/trained_wav2lip_288x288/checkpoint_step000000001.pth  --face /tmp/face_video/VID20230623143819.mp4 --audio /tmp/audio/测试wav2lip.mp3\n",
    "#./s5cmd sync ./results/result_voice.mp4  s3://${sagemaker_default_bucket}/models/wav2lip_288x288/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6372dad3-4388-4925-91c4-a44b2f95bca0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: wav2lip-288x288-demo-2023-10-20-13-51-47-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-20 13:54:12 Starting - Starting the training job......\n",
      "2023-10-20 13:54:49 Starting - Preparing the instances for training.........\n",
      "2023-10-20 13:56:22 Downloading - Downloading input data...\n",
      "2023-10-20 13:56:47 Training - Downloading the training image..................\n",
      "2023-10-20 13:59:58 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:51,757 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:51,818 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:51,829 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:51,832 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:52,964 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:53,037 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:53,111 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:53,122 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"data_root\": \"/opt/ml/input/data/data_root\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"data_root\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"wav2lip-288x288-demo-2023-10-20-13-51-47-200\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-687912291502/wav2lip-288x288-demo-2023-10-20-13-51-47-200/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-distribute.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-distribute.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-distribute.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"data_root\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"data_root\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-distribute.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=192\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-687912291502/wav2lip-288x288-demo-2023-10-20-13-51-47-200/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"data_root\":\"/opt/ml/input/data/data_root\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"data_root\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"wav2lip-288x288-demo-2023-10-20-13-51-47-200\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-687912291502/wav2lip-288x288-demo-2023-10-20-13-51-47-200/source/sourcedir.tar.gz\",\"module_name\":\"train-distribute.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-distribute.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATA_ROOT=/opt/ml/input/data/data_root\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./train-distribute.sh \"\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:00:54.859: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:54,863 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-10-20 14:00:54,885 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/.ipynb_checkpoints/00009-checkpoint.txt /tmp/main2/5536876846942893978/.ipynb_checkpoints/00009-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/.ipynb_checkpoints/00001-checkpoint.txt /tmp/main2/5536876846942893978/.ipynb_checkpoints/00001-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/.ipynb_checkpoints/00056-checkpoint.txt /tmp/main2/5536876846942893978/.ipynb_checkpoints/00056-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/.ipynb_checkpoints/00041-checkpoint.txt /tmp/main2/5536876846942893978/.ipynb_checkpoints/00041-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00001.txt /tmp/main2/5536876846942893978/00001.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00013.txt /tmp/main2/5536876846942893978/00013.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/.ipynb_checkpoints/00059-checkpoint.txt /tmp/main2/5536876846942893978/.ipynb_checkpoints/00059-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00002.txt /tmp/main2/5536876846942893978/00002.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00006.txt /tmp/main2/5536876846942893978/00006.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00013.mp4 /tmp/main2/5536876846942893978/00013.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00019.txt /tmp/main2/5536876846942893978/00019.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00010.mp4 /tmp/main2/5536876846942893978/00010.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00060.txt /tmp/main2/5536876846942893978/00060.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00026.txt /tmp/main2/5536876846942893978/00026.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00034.txt /tmp/main2/5536876846942893978/00034.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00007.txt /tmp/main2/5536876846942893978/00007.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00041.txt /tmp/main2/5536876846942893978/00041.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00001.txt /tmp/main2/5540197286159433545/00001.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/.ipynb_checkpoints/00007-checkpoint.txt /tmp/main2/5540197286159433545/.ipynb_checkpoints/00007-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00032.txt /tmp/main2/5536876846942893978/00032.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00012.txt /tmp/main2/5540197286159433545/00012.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00010.txt /tmp/main2/5536876846942893978/00010.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00058.txt /tmp/main2/5536876846942893978/00058.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00030.txt /tmp/main2/5536876846942893978/00030.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00048.txt /tmp/main2/5536876846942893978/00048.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00013.txt /tmp/main2/5540197286159433545/00013.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00009.txt /tmp/main2/5536876846942893978/00009.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00011.txt /tmp/main2/5536876846942893978/00011.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00024.txt /tmp/main2/5536876846942893978/00024.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00035.txt /tmp/main2/5536876846942893978/00035.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00018.txt /tmp/main2/5536876846942893978/00018.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00044.txt /tmp/main2/5536876846942893978/00044.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00015.txt /tmp/main2/5536876846942893978/00015.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00040.txt /tmp/main2/5536876846942893978/00040.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00014.txt /tmp/main2/5536876846942893978/00014.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00056.txt /tmp/main2/5536876846942893978/00056.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00036.txt /tmp/main2/5536876846942893978/00036.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00068.txt /tmp/main2/5536876846942893978/00068.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00059.txt /tmp/main2/5536876846942893978/00059.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00024.mp4 /tmp/main2/5536876846942893978/00024.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00012.txt /tmp/main2/5536876846942893978/00012.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00072.txt /tmp/main2/5536876846942893978/00072.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00070.txt /tmp/main2/5536876846942893978/00070.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00007.txt /tmp/main2/5540197286159433545/00007.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00019.mp4 /tmp/main2/5536876846942893978/00019.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/.ipynb_checkpoints/00012-checkpoint.txt /tmp/main2/5540197286159433545/.ipynb_checkpoints/00012-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00002.mp4 /tmp/main2/5536876846942893978/00002.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00065.txt /tmp/main2/5536876846942893978/00065.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/.ipynb_checkpoints/00001-checkpoint.txt /tmp/main2/5540197286159433545/.ipynb_checkpoints/00001-checkpoint.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00060.mp4 /tmp/main2/5536876846942893978/00060.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00073.txt /tmp/main2/5536876846942893978/00073.txt\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00006.mp4 /tmp/main2/5536876846942893978/00006.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00001.mp4 /tmp/main2/5536876846942893978/00001.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00009.mp4 /tmp/main2/5536876846942893978/00009.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00065.mp4 /tmp/main2/5536876846942893978/00065.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00041.mp4 /tmp/main2/5536876846942893978/00041.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00014.mp4 /tmp/main2/5536876846942893978/00014.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00015.mp4 /tmp/main2/5536876846942893978/00015.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00056.mp4 /tmp/main2/5536876846942893978/00056.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00012.mp4 /tmp/main2/5536876846942893978/00012.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00026.mp4 /tmp/main2/5536876846942893978/00026.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00048.mp4 /tmp/main2/5536876846942893978/00048.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00012.mp4 /tmp/main2/5540197286159433545/00012.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00001.mp4 /tmp/main2/5540197286159433545/00001.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00044.mp4 /tmp/main2/5536876846942893978/00044.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00059.mp4 /tmp/main2/5536876846942893978/00059.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00058.mp4 /tmp/main2/5536876846942893978/00058.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00040.mp4 /tmp/main2/5536876846942893978/00040.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00034.mp4 /tmp/main2/5536876846942893978/00034.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00032.mp4 /tmp/main2/5536876846942893978/00032.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00035.mp4 /tmp/main2/5536876846942893978/00035.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00011.mp4 /tmp/main2/5536876846942893978/00011.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00036.mp4 /tmp/main2/5536876846942893978/00036.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00072.mp4 /tmp/main2/5536876846942893978/00072.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00068.mp4 /tmp/main2/5536876846942893978/00068.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00073.mp4 /tmp/main2/5536876846942893978/00073.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00013.mp4 /tmp/main2/5540197286159433545/00013.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00030.mp4 /tmp/main2/5536876846942893978/00030.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00018.mp4 /tmp/main2/5536876846942893978/00018.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00007.mp4 /tmp/main2/5536876846942893978/00007.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5540197286159433545/00007.mp4 /tmp/main2/5540197286159433545/00007.mp4\u001b[0m\n",
      "\u001b[34mcp s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/train_data/main2/5536876846942893978/00070.mp4 /tmp/main2/5536876846942893978/00070.mp4\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: librosa>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 1)) (0.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.1 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 2)) (1.23.5)\u001b[0m\n",
      "\u001b[34mCollecting opencv-contrib-python>=4.2.0.34\u001b[0m\n",
      "\u001b[34mDownloading opencv_contrib_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 MB 37.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.1.0.25 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 4)) (4.7.0.68)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 5)) (1.13.1+cu117)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 6)) (0.14.1+cu117)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.45.0 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 7)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba>=0.48 in /opt/conda/lib/python3.9/site-packages (from -r ./requirements.txt (line 8)) (0.56.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.9/site-packages (from librosa>=0.7.0->-r ./requirements.txt (line 1)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.1.0->-r ./requirements.txt (line 5)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision>=0.3.0->-r ./requirements.txt (line 6)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision>=0.3.0->-r ./requirements.txt (line 6)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba>=0.48->-r ./requirements.txt (line 8)) (65.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.9/site-packages (from numba>=0.48->-r ./requirements.txt (line 8)) (0.39.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.0->librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision>=0.3.0->-r ./requirements.txt (line 6)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision>=0.3.0->-r ./requirements.txt (line 6)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision>=0.3.0->-r ./requirements.txt (line 6)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision>=0.3.0->-r ./requirements.txt (line 6)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa>=0.7.0->-r ./requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa>=0.7.0->-r ./requirements.txt (line 1)) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.7.0->-r ./requirements.txt (line 1)) (2.21)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: opencv-contrib-python\u001b[0m\n",
      "\u001b[34mSuccessfully installed opencv-contrib-python-4.8.1.78\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.3\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m--------preprocess wav-----------\u001b[0m\n",
      "\u001b[34mStarted processing for /tmp/main2 with 1 GPUs\u001b[0m\n",
      "\u001b[34m0%|          | 0/37 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 1/37 [00:02<01:46,  2.97s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 2/37 [00:03<01:00,  1.74s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/37 [00:04<00:40,  1.20s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 4/37 [00:05<00:38,  1.16s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 5/37 [00:05<00:28,  1.11it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 6/37 [00:06<00:27,  1.13it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/37 [00:07<00:23,  1.29it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/37 [00:07<00:20,  1.45it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 9/37 [00:08<00:21,  1.33it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 10/37 [00:09<00:19,  1.38it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 11/37 [00:10<00:20,  1.24it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 12/37 [00:11<00:18,  1.34it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 13/37 [00:11<00:17,  1.38it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 14/37 [00:12<00:15,  1.45it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 15/37 [00:13<00:17,  1.24it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 16/37 [00:13<00:13,  1.50it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 17/37 [00:13<00:11,  1.82it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 18/37 [00:15<00:13,  1.40it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 19/37 [00:15<00:11,  1.54it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 20/37 [00:16<00:11,  1.46it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 21/37 [00:16<00:08,  1.78it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 22/37 [00:18<00:12,  1.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 23/37 [00:18<00:11,  1.26it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 24/37 [00:19<00:08,  1.49it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 25/37 [00:19<00:07,  1.58it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 26/37 [00:20<00:05,  1.86it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 27/37 [00:20<00:06,  1.61it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 28/37 [00:21<00:05,  1.73it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 29/37 [00:21<00:04,  1.92it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 30/37 [00:22<00:03,  2.11it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 31/37 [00:22<00:03,  1.75it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 32/37 [00:23<00:02,  1.72it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 33/37 [00:24<00:02,  1.72it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 34/37 [00:25<00:02,  1.37it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 35/37 [00:25<00:01,  1.36it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 36/37 [00:26<00:00,  1.35it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 37/37 [00:27<00:00,  1.38it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 37/37 [00:27<00:00,  1.35it/s]\u001b[0m\n",
      "\u001b[34mDumping audios...\u001b[0m\n",
      "\u001b[34m0%|          | 0/37 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 1/37 [00:00<00:04,  7.28it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 2/37 [00:00<00:04,  7.63it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 3/37 [00:00<00:04,  7.77it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 4/37 [00:00<00:04,  7.85it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 5/37 [00:00<00:04,  7.93it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 6/37 [00:00<00:03,  7.90it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 7/37 [00:00<00:03,  7.91it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 8/37 [00:01<00:03,  7.96it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 9/37 [00:01<00:03,  7.97it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 10/37 [00:01<00:03,  7.99it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 11/37 [00:01<00:03,  8.00it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 12/37 [00:01<00:03,  7.99it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 13/37 [00:01<00:02,  8.01it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 14/37 [00:01<00:02,  8.01it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 15/37 [00:01<00:02,  8.00it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 16/37 [00:02<00:02,  8.04it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 17/37 [00:02<00:02,  8.07it/s]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 18/37 [00:02<00:02,  8.05it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 19/37 [00:02<00:02,  8.03it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 20/37 [00:02<00:02,  8.02it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 21/37 [00:02<00:01,  8.05it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 22/37 [00:02<00:01,  8.02it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 23/37 [00:02<00:01,  8.04it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 24/37 [00:03<00:01,  8.06it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 25/37 [00:03<00:01,  8.07it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 26/37 [00:03<00:01,  8.05it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 27/37 [00:03<00:01,  8.04it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 28/37 [00:03<00:01,  8.07it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 29/37 [00:03<00:00,  8.08it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 30/37 [00:03<00:00,  8.07it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 31/37 [00:03<00:00,  8.07it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 32/37 [00:03<00:00,  8.08it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 33/37 [00:04<00:00,  8.08it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 34/37 [00:04<00:00,  8.05it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 35/37 [00:04<00:00,  8.07it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 36/37 [00:04<00:00,  8.11it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 37/37 [00:04<00:00,  8.08it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 37/37 [00:04<00:00,  8.01it/s]\u001b[0m\n",
      "\u001b[34mfinished preprocess\u001b[0m\n",
      "\u001b[34m--------prepare tain list--------\u001b[0m\n",
      "\u001b[34mfinished train list prepare\u001b[0m\n",
      "\u001b[34m--------train the expert discriminator------\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:38,138] [WARNING] [runner.py:155:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:38,190] [INFO] [runner.py:438:main] cmd = /opt/conda/bin/python3.9 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 ./color_syncnet_dist_train.py --data_root /tmp/lrs2_preprocessed2/ --checkpoint_dir /tmp/trained_syncnet/ --deepspeed --deepspeed_config ds_config.json\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:96:main] 0 NCCL_VERSION=2.14.3\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:96:main] 0 NCCL_SOCKET_IFNAME=eth0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:96:main] 0 NCCL_DEBUG=WARN\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:96:main] 0 NCCL_IB_DISABLE=1\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:103:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:109:main] nnodes=1, num_local_procs=8, node_rank=0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:122:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:123:main] dist_world_size=8\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:39,468] [INFO] [launch.py:125:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34muse_cuda: True\u001b[0m\n",
      "\u001b[34mtrain_dataset: 66\u001b[0m\n",
      "\u001b[34mtest_dataset: 66\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,327] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,569] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,598] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,599] [INFO] [distributed.py:48:init_distributed] Initializing torch distributed with backend: nccl\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,613] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,633] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,664] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,669] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34mtotal trainable params 19881059\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:43,670] [INFO] [logging.py:69:log_dist] [Rank -1] DeepSpeed info: version=0.6.1+06f2048, git-hash=06f2048, git-branch=HEAD\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:429: UserWarning: torch.distributed.distributed_c10d._get_global_rank is deprecated please use torch.distributed.distributed_c10d.get_global_rank instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mNCCL version 2.14.3+cuda11.7\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,897] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,897] [INFO] [engine.py:1082:_configure_optimizer] Removing param_group that has no 'params' in the client Optimizer\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,897] [INFO] [engine.py:1088:_configure_optimizer] Using client Optimizer as basic optimizer\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [engine.py:1104:_configure_optimizer] DeepSpeed Basic Optimizer = Adam\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [engine.py:794:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f22e0905340>\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,903] [INFO] [config.py:1069:print] DeepSpeedEngine configuration:\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   amp_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   amp_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": null, \n",
      "    \"exps_dir\": null, \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   bfloat16_enabled ............. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   checkpoint_tag_validation_enabled  True\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   checkpoint_tag_validation_fail  False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   communication_data_type ...... None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   curriculum_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   curriculum_params ............ False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   dataloader_drop_last ......... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   disable_allgather ............ False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   dump_state ................... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   dynamic_loss_scale_args ...... None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   eigenvalue_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   eigenvalue_gas_boundary_resolution  1\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,904] [INFO] [config.py:1073:print]   eigenvalue_layer_name ........ bert.encoder.layer\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   eigenvalue_layer_num ......... 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   eigenvalue_max_iter .......... 100\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   eigenvalue_stability ......... 1e-06\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   eigenvalue_tol ............... 0.01\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   eigenvalue_verbose ........... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   elasticity_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   fp16_enabled ................. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   fp16_master_weights_and_gradients  False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   fp16_mixed_quantize .......... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   global_rank .................. 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   gradient_accumulation_steps .. 4\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   gradient_clipping ............ 0.0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   gradient_predivide_factor .... 1.0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   initial_dynamic_scale ........ 4294967296\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   loss_scale ................... 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   memory_breakdown ............. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   optimizer_legacy_fusion ...... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   optimizer_name ............... adam\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   pld_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   pld_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   prescale_gradients ........... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_change_rate ......... 0.001\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_groups .............. 1\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_offset .............. 1000\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_period .............. 1000\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_rounding ............ 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_start_bits .......... 16\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_target_bits ......... 8\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_training_enabled .... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_type ................ 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   quantize_verbose ............. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   scheduler_name ............... WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   sparse_attention ............. None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   sparse_gradients_enabled ..... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   steps_per_print .............. 2000\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   tensorboard_enabled .......... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   tensorboard_job_name ......... DeepSpeedJobName\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   tensorboard_output_path ...... \u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   train_batch_size ............. 64\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   train_micro_batch_size_per_gpu  2\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   use_quantizer_kernel ......... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   wall_clock_breakdown ......... False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,905] [INFO] [config.py:1073:print]   world_size ................... 8\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,906] [INFO] [config.py:1073:print]   zero_allow_untested_optimizer  False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,906] [INFO] [config.py:1073:print]   zero_config .................. {\n",
      "    \"stage\": 0, \n",
      "    \"contiguous_gradients\": false, \n",
      "    \"contiguous_parameters\": false, \n",
      "    \"reduce_scatter\": true, \n",
      "    \"reduce_bucket_size\": 5.000000e+08, \n",
      "    \"allgather_partitions\": true, \n",
      "    \"allgather_bucket_size\": 5.000000e+08, \n",
      "    \"overlap_comm\": false, \n",
      "    \"load_from_fp32_weights\": true, \n",
      "    \"elastic_checkpoint\": false, \n",
      "    \"offload_param\": null, \n",
      "    \"offload_optimizer\": null, \n",
      "    \"sub_group_size\": 1.000000e+09, \n",
      "    \"prefetch_bucket_size\": 5.000000e+07, \n",
      "    \"param_persistence_threshold\": 1.000000e+05, \n",
      "    \"max_live_parameters\": 1.000000e+09, \n",
      "    \"max_reuse_distance\": 1.000000e+09, \n",
      "    \"gather_16bit_weights_on_model_save\": false, \n",
      "    \"ignore_unused_parameters\": true, \n",
      "    \"round_robin_gradients\": false, \n",
      "    \"legacy_stage1\": false, \n",
      "    \"comm_small_bucket_size\": 5.000000e+08, \n",
      "    \"zero2d_local_shard\": false, \n",
      "    \"zero2d_shard_size\": -1, \n",
      "    \"zero2d_hierarchy_allgather\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,906] [INFO] [config.py:1073:print]   zero_enabled ................. False\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,906] [INFO] [config.py:1073:print]   zero_optimization_stage ...... 0\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:01:45,906] [INFO] [config.py:1075:print]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"auto_cast\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.001, \n",
      "            \"betas\": [0.8, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 3e-07\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 0.001, \n",
      "            \"warmup_num_steps\": 1000\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 0\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 4, \n",
      "    \"gradient_clipping\": 0.0, \n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 64, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"wall_clock_breakdown\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py39_cu117/utils...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py39_cu117 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py39_cu117/utils/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module utils...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34m[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /opt/conda/lib/python3.9/site-packages/torch/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /opt/conda/lib/python3.9/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o\u001b[0m\n",
      "\u001b[34m[2/2] c++ flatten_unflatten.o -shared -L/opt/conda/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.840719223022461 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.823026657104492 seconds\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.822317838668823 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.822858095169067 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.823713779449463 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.822572231292725 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.822910070419312 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module utils...\u001b[0m\n",
      "\u001b[34mTime to load utils op: 15.922128915786743 seconds\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:02.965: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:02.972: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:02.997 algo-1:8684 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.003 algo-1:8685 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.061: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.080: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.092 algo-1:8689 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.094: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.095: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.097: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.101: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.113 algo-1:8682 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.128 algo-1:8683 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.128 algo-1:8688 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.129 algo-1:8687 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.134 algo-1:8686 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.332 algo-1:8685 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.351 algo-1:8684 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.419 algo-1:8689 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.505 algo-1:8683 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.520 algo-1:8682 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.525 algo-1:8687 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.528 algo-1:8686 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:03.537 algo-1:8688 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9915027022361755: : 0it [00:04, ?it/s]#015Loss: 0.9915027022361755: : 1it [00:04,  4.11s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8915383219718933: : 1it [00:04,  4.11s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8915383219718933: : 2it [00:04,  2.10s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.935989499092102: : 0it [00:04, ?it/s]#015Loss: 0.935989499092102: : 1it [00:04,  4.03s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8610312938690186: : 1it [00:04,  4.03s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8610312938690186: : 2it [00:04,  2.06s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1580182313919067: : 0it [00:04, ?it/s]#015Loss: 1.1580182313919067: : 1it [00:04,  4.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7137047797441483: : 1it [00:04,  4.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7137047797441483: : 2it [00:04,  2.36s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0877448320388794: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0877448320388794: : 1it [00:02,  2.36s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9864660501480103: : 0it [00:06, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9864660501480103: : 1it [00:06,  6.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9132711887359619: : 1it [00:06,  6.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9132711887359619: : 2it [00:06,  3.31s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1746208667755127: : 0it [00:06, ?it/s]#015Loss: 1.1746208667755127: : 1it [00:06,  6.77s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.998420923948288: : 1it [00:06,  6.77s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.998420923948288: : 2it [00:06,  3.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1580708026885986: : 0it [00:06, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1580708026885986: : 1it [00:06,  6.89s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.3029546737670898: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.3029546737670898: : 1it [00:02,  2.59s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0137622654438019: : 1it [00:06,  6.89s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.012763261795044: : 0it [00:02, ?it/s]#015Loss: 1.012763261795044: : 1it [00:02,  2.21s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0137622654438019: : 2it [00:06,  3.48s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0212730169296265: : 0it [00:07, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0212730169296265: : 1it [00:07,  7.14s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.16769939661026: : 1it [00:07,  7.14s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.16769939661026: : 2it [00:07,  3.63s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8257911205291748: : 0it [00:07, ?it/s]#015Loss: 0.8257911205291748: : 1it [00:07,  7.51s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8191609680652618: : 1it [00:07,  7.51s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8191609680652618: : 2it [00:07,  3.80s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0806010961532593: : 0it [00:02, ?it/s]#015Loss: 1.0806010961532593: : 1it [00:02,  2.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0489146709442139: : 0it [00:03, ?it/s]#015Loss: 1.0489146709442139: : 1it [00:03,  3.05s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0143675804138184: : 0it [00:03, ?it/s]#015Loss: 1.0143675804138184: : 1it [00:03,  3.54s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0547500848770142: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0547500848770142: : 1it [00:03,  3.01s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8901289105415344: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8901289105415344: : 1it [00:03,  3.25s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.99031001329422: : 1it [00:04,  3.54s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.99031001329422: : 2it [00:04,  1.88s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9046058654785156: : 1it [00:03,  3.01s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9046058654785156: : 2it [00:03,  1.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9336304664611816: : 1it [00:06,  2.21s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9336304664611816: : 2it [00:06,  3.34s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.089574247598648: : 1it [00:06,  2.59s/it] #015Loss: 1.089574247598648: : 2it [00:06,  3.52s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8555841743946075: : 1it [00:03,  3.25s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.955603837966919: : 1it [00:03,  2.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.955603837966919: : 2it [00:03,  1.87s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6945886015892029: : 1it [00:06,  2.36s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6945886015892029: : 2it [00:06,  3.66s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9289985597133636: : 1it [00:04,  3.05s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9289985597133636: : 2it [00:04,  1.83s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.99031001329422: : 2it [00:04,  2.18s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.089574247598648: : 2it [00:06,  3.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.955603837966919: : 2it [00:04,  2.04s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8555841743946075: : 2it [00:03,  1.73s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9046058654785156: : 2it [00:03,  1.88s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6945886015892029: : 2it [00:07,  3.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9289985597133636: : 2it [00:04,  2.08s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9336304664611816: : 2it [00:06,  3.24s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]#0150it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0779919624328613: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0779919624328613: : 1it [00:03,  3.62s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.3594186902046204: : 1it [00:03,  3.62s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.3594186902046204: : 2it [00:03,  1.93s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8945469856262207: : 0it [00:04, ?it/s]#015Loss: 0.8945469856262207: : 1it [00:04,  4.46s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0487940311431885: : 1it [00:04,  4.46s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0487940311431885: : 2it [00:04,  2.30s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9352980852127075: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9352980852127075: : 1it [00:04,  4.80s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9292690753936768: : 1it [00:04,  4.80s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0182814598083496: : 0it [00:04, ?it/s]#015Loss: 1.0182814598083496: : 1it [00:04,  4.90s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.102433681488037: : 1it [00:04,  4.90s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9292690753936768: : 2it [00:04,  2.47s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.102433681488037: : 2it [00:05,  2.52s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9964355826377869: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9964355826377869: : 1it [00:05,  5.07s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8740423619747162: : 1it [00:05,  5.07s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1039458513259888: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1039458513259888: : 1it [00:05,  5.16s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.714513435959816: : 1it [00:05,  5.16s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8740423619747162: : 2it [00:05,  2.59s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.714513435959816: : 2it [00:05,  2.64s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9046361446380615: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9046361446380615: : 1it [00:05,  5.34s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5711067020893097: : 1it [00:05,  5.34s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5711067020893097: : 2it [00:05,  2.75s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.940613865852356: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.940613865852356: : 1it [00:05,  5.59s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.87703937292099: : 1it [00:05,  5.59s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.87703937292099: : 2it [00:05,  2.91s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.2108056545257568: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.2108056545257568: : 1it [00:02,  2.66s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7821232080459595: : 0it [00:03, ?it/s]#015Loss: 0.7821232080459595: : 1it [00:03,  3.64s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0812294483184814: : 0it [00:04, ?it/s]#015Loss: 1.0812294483184814: : 1it [00:04,  4.32s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8670270442962646: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8670270442962646: : 1it [00:03,  3.01s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0469281673431396: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0469281673431396: : 1it [00:03,  3.98s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.068686604499817: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.068686604499817: : 1it [00:04,  4.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9795811176300049: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9795811176300049: : 1it [00:04,  4.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9803705215454102: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9803705215454102: : 1it [00:04,  4.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2049254179000854: : 1it [00:05,  4.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2049254179000854: : 2it [00:05,  2.14s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.172899842262268: : 1it [00:05,  4.32s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.172899842262268: : 2it [00:05,  2.46s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5839409530162811: : 1it [00:04,  3.01s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5839409530162811: : 2it [00:04,  1.84s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9029375314712524: : 1it [00:04,  3.98s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9029375314712524: : 2it [00:04,  2.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8969436585903168: : 1it [00:04,  4.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8969436585903168: : 2it [00:04,  1.93s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7635987848043442: : 1it [00:06,  2.66s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7635987848043442: : 2it [00:06,  3.15s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7689738869667053: : 1it [00:05,  3.64s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7689738869667053: : 2it [00:05,  2.41s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6677787750959396: : 1it [00:04,  4.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6677787750959396: : 2it [00:04,  2.11s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6677787750959396: : 2it [00:04,  2.47s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7635987848043442: : 2it [00:06,  3.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2049254179000854: : 2it [00:05,  2.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9029375314712524: : 2it [00:04,  2.47s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8969436585903168: : 2it [00:04,  2.38s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5839409530162811: : 2it [00:04,  2.09s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.172899842262268: : 2it [00:05,  2.81s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7689738869667053: : 2it [00:05,  2.66s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0467760562896729: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0467760562896729: : 1it [00:02,  2.68s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0560399293899536: : 0it [00:03, ?it/s]#015Loss: 1.0560399293899536: : 1it [00:03,  3.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9144122004508972: : 0it [00:03, ?it/s]#015Loss: 0.9144122004508972: : 1it [00:03,  3.86s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8232460021972656: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8232460021972656: : 1it [00:04,  4.12s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9612548351287842: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9612548351287842: : 1it [00:04,  4.31s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1503593921661377: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1503593921661377: : 1it [00:04,  4.59s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0989880561828613: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0989880561828613: : 1it [00:04,  4.84s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.924680233001709: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.924680233001709: : 1it [00:04,  4.90s/it]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:30,665] [INFO] [logging.py:69:log_dist] [Rank 0] Saving model checkpoint: /tmp/trained_syncnet/global_step2/mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[34mSaved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint:  /tmp/trained_syncnet/ /tmp/trained_syncnet/  /tmp/trained_syncnet/ /tmp/trained_syncnet//tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34m/tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mSaved checkpoint:\u001b[0m\n",
      "\u001b[34m/tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mSaved checkpoint: /tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mLoss: 0.958518773317337: : 1it [00:05,  4.84s/it] #015Loss: 1.3052628636360168: : 1it [00:05,  4.59s/it]#015Loss: 0.8533866107463837: : 1it [00:05,  3.86s/it]#015Loss: 1.1820385456085205: : 1it [00:05,  4.12s/it]#015Loss: 0.958518773317337: : 2it [00:05,  2.29s/it]#015Loss: 0.9559397995471954: : 1it [00:05,  3.71s/it]#015Loss: 0.7106007039546967: : 1it [00:05,  2.68s/it]#015Loss: 1.3052628636360168: : 2it [00:05,  2.33s/it]#015Loss: 0.8533866107463837: : 2it [00:05,  2.50s/it]#015Loss: 1.1820385456085205: : 2it [00:05,  2.42s/it]#015Loss: 0.9559397995471954: : 2it [00:05,  2.49s/it]#015Loss: 0.7106007039546967: : 2it [00:05,  2.68s/it]#015Loss: 0.8431408107280731: : 1it [00:05,  4.90s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8431408107280731: : 2it [00:05,  2.27s/it]#015Loss: 0.6067034751176834: : 1it [00:05,  4.31s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6067034751176834: : 2it [00:05,  2.40s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.958518773317337: : 2it [00:05,  2.73s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8533866107463837: : 2it [00:05,  2.76s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1820385456085205: : 2it [00:05,  2.74s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6067034751176834: : 2it [00:05,  2.75s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9559397995471954: : 2it [00:05,  2.74s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7106007039546967: : 2it [00:05,  2.75s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.3052628636360168: : 2it [00:05,  2.74s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8431408107280731: : 2it [00:05,  2.74s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.01653254032135: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.01653254032135: : 1it [00:02,  2.75s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8841935396194458: : 0it [00:02, ?it/s]#015Loss: 0.8841935396194458: : 1it [00:02,  2.95s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9050845503807068: : 0it [00:03, ?it/s]#015Loss: 0.9050845503807068: : 1it [00:03,  3.31s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0396480560302734: : 0it [00:03, ?it/s]#015Loss: 1.0396480560302734: : 1it [00:03,  3.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0974831581115723: : 0it [00:05, ?it/s]#015Loss: 1.0974831581115723: : 1it [00:05,  5.08s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.949385941028595: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.949385941028595: : 1it [00:05,  5.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8730460405349731: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.8730460405349731: : 1it [00:05,  5.27s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9810633659362793: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9810633659362793: : 1it [00:05,  5.30s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.135174185037613: : 1it [00:05,  5.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.135174185037613: : 2it [00:05,  2.27s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6182812452316284: : 1it [00:05,  2.95s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6182812452316284: : 2it [00:05,  2.67s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8521286249160767: : 1it [00:05,  3.31s/it]#015Loss: 0.896947592496872: : 1it [00:05,  3.60s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8521286249160767: : 2it [00:05,  2.62s/it]#015Loss: 0.896947592496872: : 2it [00:05,  2.58s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9620507955551147: : 1it [00:05,  5.08s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9620507955551147: : 2it [00:05,  2.28s/it]#015Loss: 1.2676779627799988: : 1it [00:05,  5.30s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2676779627799988: : 2it [00:05,  2.24s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9099633991718292: : 1it [00:05,  2.75s/it]#015Loss: 0.9099633991718292: : 2it [00:05,  2.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8345190286636353: : 1it [00:05,  5.27s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8345190286636353: : 2it [00:05,  2.28s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8521286249160767: : 2it [00:05,  2.77s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.896947592496872: : 2it [00:05,  2.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.135174185037613: : 2it [00:05,  2.76s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8345190286636353: : 2it [00:05,  2.79s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2676779627799988: : 2it [00:05,  2.77s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9099633991718292: : 2it [00:05,  2.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9620507955551147: : 2it [00:05,  2.77s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6182812452316284: : 2it [00:05,  2.78s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9720480442047119: : 0it [00:02, ?it/s]#015Loss: 0.9720480442047119: : 1it [00:02,  2.85s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8639459908008575: : 1it [00:02,  2.85s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.209713101387024: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.209713101387024: : 1it [00:02,  2.85s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0374289155006409: : 1it [00:02,  2.85s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8639459908008575: : 2it [00:03,  1.55s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0374289155006409: : 2it [00:03,  1.53s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0965683460235596: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0965683460235596: : 1it [00:03,  3.65s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9396159052848816: : 1it [00:03,  3.65s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9396159052848816: : 2it [00:03,  1.93s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.09535813331604: : 0it [00:03, ?it/s]#015Loss: 1.09535813331604: : 1it [00:03,  3.93s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2592903971672058: : 1it [00:04,  3.93s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.2592903971672058: : 2it [00:04,  2.12s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.024705410003662: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.024705410003662: : 1it [00:04,  4.55s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.655963122844696: : 1it [00:04,  4.55s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.655963122844696: : 2it [00:04,  2.42s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0954604148864746: : 0it [00:04, ?it/s]#015Loss: 1.0954604148864746: : 1it [00:04,  4.90s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6762978732585907: : 1it [00:04,  4.90s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1550953388214111: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1550953388214111: : 1it [00:04,  4.96s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.03977769613266: : 1it [00:04,  4.96s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6762978732585907: : 2it [00:05,  2.55s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.03977769613266: : 2it [00:05,  2.63s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.166752815246582: : 0it [00:05, ?it/s]#015Loss: 1.166752815246582: : 1it [00:05,  5.65s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9799696505069733: : 1it [00:05,  5.65s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9799696505069733: : 2it [00:05,  2.96s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1618199348449707: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1618199348449707: : 1it [00:02,  2.74s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9119618535041809: : 0it [00:03, ?it/s]#015Loss: 0.9119618535041809: : 1it [00:03,  3.27s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8137377500534058: : 0it [00:02, ?it/s]#015Loss: 0.8137377500534058: : 1it [00:02,  2.76s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.019781231880188: : 0it [00:02, ?it/s]#015Loss: 1.019781231880188: : 1it [00:02,  2.67s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.027787208557129: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.027787208557129: : 1it [00:02,  2.22s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0745697021484375: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0745697021484375: : 1it [00:03,  3.66s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0891895294189453: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0891895294189453: : 1it [00:03,  3.57s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0556652545928955: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0556652545928955: : 1it [00:04,  4.02s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7958143651485443: : 1it [00:05,  2.76s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7958143651485443: : 2it [00:05,  2.68s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8747087121009827: : 1it [00:05,  3.27s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8747087121009827: : 2it [00:05,  2.94s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9546932876110077: : 1it [00:06,  2.74s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9546932876110077: : 2it [00:06,  3.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9537826180458069: : 1it [00:03,  2.22s/it]#015Loss: 0.9537826180458069: : 2it [00:03,  1.55s/it]#015Loss: 1.148986279964447: : 1it [00:04,  4.02s/it] #015Loss: 0.9559467136859894: : 1it [00:03,  3.57s/it]#015Loss: 1.148986279964447: : 2it [00:04,  1.72s/it]#015Loss: 0.9559467136859894: : 2it [00:03,  1.67s/it]#015Loss: 0.705032229423523: : 1it [00:04,  3.66s/it] #015Loss: 0.705032229423523: : 2it [00:04,  1.78s/it]#015Loss: 0.895393580198288: : 1it [00:04,  2.67s/it]#015Loss: 0.895393580198288: : 2it [00:04,  2.44s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9546932876110077: : 2it [00:06,  3.13s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.148986279964447: : 2it [00:04,  2.12s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.7958143651485443: : 2it [00:05,  2.75s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.705032229423523: : 2it [00:04,  2.12s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8747087121009827: : 2it [00:06,  3.05s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9559467136859894: : 2it [00:04,  2.02s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.895393580198288: : 2it [00:05,  2.54s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9537826180458069: : 2it [00:03,  1.72s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9178286790847778: : 0it [00:02, ?it/s]#015Loss: 0.9178286790847778: : 1it [00:02,  2.88s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.58316520601511: : 1it [00:02,  2.88s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.58316520601511: : 2it [00:03,  1.51s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1072099208831787: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1072099208831787: : 1it [00:03,  3.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9544535279273987: : 1it [00:03,  3.78s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9544535279273987: : 2it [00:04,  2.05s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0567039251327515: : 0it [00:04, ?it/s]#015Loss: 1.0567039251327515: : 1it [00:04,  4.12s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9484300017356873: : 1it [00:04,  4.12s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9484300017356873: : 2it [00:04,  2.14s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0624585151672363: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0624585151672363: : 1it [00:04,  4.29s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.2321881651878357: : 1it [00:04,  4.29s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.2321881651878357: : 2it [00:04,  2.28s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1158907413482666: : 0it [00:04, ?it/s]#015Loss: 1.1158907413482666: : 1it [00:04,  4.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2280198335647583: : 1it [00:04,  4.71s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.2280198335647583: : 2it [00:04,  2.43s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.010501503944397: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.010501503944397: : 1it [00:05,  5.21s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0897825360298157: : 1it [00:05,  5.21s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0897825360298157: : 2it [00:05,  2.68s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0931446552276611: : 0it [00:05, ?it/s]#015Loss: 1.0931446552276611: : 1it [00:05,  5.53s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.926079273223877: : 1it [00:05,  5.53s/it] #015Loss: 0.926079273223877: : 2it [00:05,  2.34s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.926079273223877: : 2it [00:05,  2.89s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1184275150299072: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1184275150299072: : 1it [00:02,  2.64s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9138232469558716: : 0it [00:05, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9138232469558716: : 1it [00:05,  5.91s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.5849123001098633: : 1it [00:05,  5.91s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.5849123001098633: : 2it [00:06,  3.07s/it]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9653317928314209: : 0it [00:03, ?it/s]#015Loss: 0.9653317928314209: : 1it [00:03,  3.10s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9182167053222656: : 0it [00:03, ?it/s]#015Loss: 0.9182167053222656: : 1it [00:03,  3.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1386357545852661: : 0it [00:02, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1386357545852661: : 1it [00:02,  2.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1224000453948975: : 0it [00:03, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.1224000453948975: : 1it [00:03,  3.29s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9359825849533081: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9359825849533081: : 1it [00:04,  4.62s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9058528542518616: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 0.9058528542518616: : 1it [00:04,  4.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.0758863687515259: : 0it [00:04, ?it/s]\u001b[0m\n",
      "\u001b[34mLoss: 1.0758863687515259: : 1it [00:04,  4.11s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:56,572] [INFO] [logging.py:69:log_dist] [Rank 0] Saving model checkpoint: /tmp/trained_syncnet/global_step5/mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[34mSaved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint:Saved checkpoint: /tmp/trained_syncnet/    /tmp/trained_syncnet//tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34m/tmp/trained_syncnet/ /tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34m/tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mLoss: 0.9476712644100189: : 1it [00:04,  4.11s/it]#015Loss: 1.1511802077293396: : 1it [00:05,  4.62s/it]#015Loss: 0.8407371044158936: : 1it [00:05,  3.43s/it]#015Loss: 0.9981403946876526: : 1it [00:06,  2.64s/it]#015Loss: 0.9450503587722778: : 1it [00:04,  3.29s/it]#015Loss: 0.950642466545105: : 1it [00:03,  2.43s/it] #015Loss: 0.9476712644100189: : 2it [00:04,  1.91s/it]#015Loss: 1.1511802077293396: : 2it [00:05,  2.31s/it]\u001b[0m\n",
      "\u001b[34mSaved checkpoint: /tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mLoss: 0.8407371044158936: : 2it [00:05,  2.73s/it]#015Loss: 0.9981403946876526: : 2it [00:06,  3.61s/it]#015Loss: 0.9450503587722778: : 2it [00:04,  1.78s/it]#015Loss: 0.950642466545105: : 2it [00:03,  1.78s/it]\u001b[0m\n",
      "\u001b[34mSaved checkpoint: /tmp/trained_syncnet/\u001b[0m\n",
      "\u001b[34mLoss: 0.6726067960262299: : 1it [00:05,  3.10s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6726067960262299: : 2it [00:05,  2.88s/it]#015Loss: 0.8694244921207428: : 1it [00:05,  4.43s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8694244921207428: : 2it [00:05,  2.19s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.950642466545105: : 2it [00:03,  1.93s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8694244921207428: : 2it [00:05,  2.59s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9450503587722778: : 2it [00:04,  2.08s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.6726067960262299: : 2it [00:05,  2.98s/it]\u001b[0m\n",
      "\u001b[34mLoss: 1.1511802077293396: : 2it [00:05,  2.73s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9981403946876526: : 2it [00:07,  3.54s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.9476712644100189: : 2it [00:04,  2.33s/it]\u001b[0m\n",
      "\u001b[34mLoss: 0.8407371044158936: : 2it [00:05,  2.93s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:58,590] [INFO] [launch.py:210:main] Process 8682 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:58,590] [INFO] [launch.py:210:main] Process 8688 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:58,591] [INFO] [launch.py:210:main] Process 8686 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:59,592] [INFO] [launch.py:210:main] Process 8689 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:59,592] [INFO] [launch.py:210:main] Process 8687 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:59,593] [INFO] [launch.py:210:main] Process 8683 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:59,593] [INFO] [launch.py:210:main] Process 8685 exits successfully.\u001b[0m\n",
      "\u001b[34m[2023-10-20 14:02:59,593] [INFO] [launch.py:210:main] Process 8684 exits successfully.\u001b[0m\n",
      "\u001b[34mfinished train syncnet\u001b[0m\n",
      "\u001b[34mtrained_syncnet_model_file: /tmp/trained_syncnet/global_step5/mp_rank_00_model_states.pt /tmp/trained_syncnet/global_step2/mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[34m--------train wav2lip-----------------------\u001b[0m\n",
      "\u001b[34musage: hq_wav2lip_train_deepspeed.py [-h] --data_root DATA_ROOT\n",
      "                                     --checkpoint_dir CHECKPOINT_DIR\n",
      "                                     --syncnet_checkpoint_path\n",
      "                                     SYNCNET_CHECKPOINT_PATH\n",
      "                                     [--checkpoint_path CHECKPOINT_PATH]\n",
      "                                     [--disc_checkpoint_path DISC_CHECKPOINT_PATH]\u001b[0m\n",
      "\u001b[34mhq_wav2lip_train_deepspeed.py: error: unrecognized arguments: /tmp/trained_syncnet/global_step2/mp_rank_00_model_states.pt\u001b[0m\n",
      "\u001b[34mfinished wav2lip\u001b[0m\n",
      "\u001b[34mName:\n",
      "  sync - sync objects\u001b[0m\n",
      "\u001b[34mUsage:\n",
      "  sync [options] source destination\u001b[0m\n",
      "\u001b[34mOptions:\u001b[0m\n",
      "\u001b[34mERROR \"sync /tmp/trained_wav2lip_288x288/ s3://sagemaker-us-west-2-687912291502/wav2lip_288x288/output/2023-10-20-14-03-03/\": given object not found\u001b[0m\n",
      "\u001b[34m--delete                       delete objects in destination but not in source (default: false)\n",
      "  --size-only                    make size of object only criteria to decide whether an object should be synced (default: false)\n",
      "  --no-follow-symlinks           do not follow symbolic links (default: false)\n",
      "  --storage-class value          set storage class for target ('STANDARD','REDUCED_REDUNDANCY','GLACIER','STANDARD_IA','ONEZONE_IA','INTELLIGENT_TIERING','DEEP_ARCHIVE')\n",
      "  --concurrency value, -c value  number of concurrent parts transferred between host and remote server (default: 5)\n",
      "  --part-size value, -p value    size of each part transferred between host and remote server, in MiB (default: 50)\n",
      "  --sse value                    perform server side encryption of the data at its destination, e.g. aws:kms\n",
      "  --sse-kms-key-id value         customer master key (CMK) id for SSE-KMS encryption; leave it out if server-side generated key is desired\n",
      "  --acl value                    set acl for target: defines granted accesses and their types on different accounts/groups, e.g. cp --acl 'public-read'\n",
      "  --cache-control value          set cache control for target: defines cache control header for object, e.g. cp --cache-control 'public, max-age=345600'\n",
      "  --expires value                set expires for target (uses RFC3339 format): defines expires header for object, e.g. cp  --expires '2024-10-01T20:30:00Z'\n",
      "  --force-glacier-transfer       force transfer of glacier objects whether they are restored or not (default: false)\n",
      "  --ignore-glacier-warnings      turns off glacier warnings: ignore errors encountered during copying, downloading and moving glacier objects (default: false)\n",
      "  --source-region value          set the region of source bucket; the region of the source bucket will be automatically discovered if --source-region is not specified\n",
      "  --destination-region value     set the region of destination bucket: the region of the destination bucket will be automatically discovered if --destination-region is not specified\n",
      "  --exclude value                exclude objects with given pattern\n",
      "  --raw                          disable the wildcard operations, useful with filenames that contains glob characters (default: false)\n",
      "  --help, -h                     show help (default: false)\n",
      "  \u001b[0m\n",
      "\u001b[34mExamples:\n",
      "  01. Sync local folder to s3 bucket\n",
      "     > s5cmd sync folder/ s3://bucket/\n",
      "  02. Sync S3 bucket to local folder\n",
      "     > s5cmd sync s3://bucket/* folder/\n",
      "  03. Sync S3 bucket objects under prefix to S3 bucket.\n",
      "     > s5cmd sync s3://sourcebucket/prefix/* s3://destbucket/\u001b[0m\n",
      "\u001b[34m04. Sync local folder to S3 but delete the files that S3 bucket has but local does not have.\n",
      "     > s5cmd sync --delete folder/ s3://bucket/\n",
      "  05. Sync S3 bucket to local folder but use size as only comparison criteria.\n",
      "     > s5cmd sync --size-only s3://bucket/* folder/\n",
      "  06. Sync a file to S3 bucket\n",
      "     > s5cmd sync myfile.gz s3://bucket/\n",
      "  07. Sync matching S3 objects to another bucket\u001b[0m\n",
      "\u001b[34m> s5cmd sync s3://bucket/*.gz s3://target-bucket/prefix/\n",
      "  08. Perform KMS Server Side Encryption of the object(s) at the destination\n",
      "     > s5cmd sync --sse aws:kms s3://bucket/object s3://target-bucket/prefix/object\n",
      "  09. Perform KMS-SSE of the object(s) at the destination using customer managed Customer Master Key (CMK) key id\n",
      "     > s5cmd sync --sse aws:kms --sse-kms-key-id <your-kms-key-id> s3://bucket/object s3://target-bucket/prefix/object\n",
      "  10. Sync all files to S3 bucket but exclude the ones with txt and gz extension\n",
      "     > s5cmd sync --exclude \"*.txt\" --exclude \"*.gz\" dir/ s3://bucket\u001b[0m\n",
      "\u001b[34m2023-10-20 14:03:03,586 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-20 14:03:03,587 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-20 14:03:03,587 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-10-20 14:03:03,587 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/bin/sh -c \"./train-distribute.sh \"\"\u001b[0m\n",
      "\u001b[34m2023-10-20 14:03:03,587 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-10-20 14:03:21 Uploading - Uploading generated training model\n",
      "2023-10-20 14:03:21 Failed - Instances not retained as a result of warmpool resource limits being exceeded\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job wav2lip-288x288-demo-2023-10-20-13-51-47-200: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"/bin/sh -c \"./train-distribute.sh \"\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 25\u001b[0m\n\u001b[1;32m     10\u001b[0m instance_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml.g5.48xlarge\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m estimator \u001b[38;5;241m=\u001b[39m Estimator(role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[1;32m     13\u001b[0m                       entry_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain-distribute.sh\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                       source_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./wav2lip_288x288/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                       debugger_hook_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m                       max_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1314\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:2597\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2597\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:4963\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   4942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   4944\u001b[0m \n\u001b[1;32m   4945\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4961\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   4962\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4963\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:6887\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   6884\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   6886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 6887\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   6889\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:6940\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6936\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6937\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6938\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6939\u001b[0m     )\n\u001b[0;32m-> 6940\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6941\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6942\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6943\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6944\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job wav2lip-288x288-demo-2023-10-20-13-51-47-200: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"\"\nCommand \"/bin/sh -c \"./train-distribute.sh \"\", exit code: 1"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "environment = {\n",
    "              'MODEL_S3_BUCKET': sagemaker_default_bucket # The bucket to store pretrained model and fine-tune model\n",
    "}\n",
    "\n",
    "base_job_name = 'wav2lip-288x288-demo'         \n",
    "\n",
    "instance_type = 'ml.g5.48xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      entry_point='train-distribute.sh',\n",
    "                      source_dir='./wav2lip_288x288/',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600,\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e673c",
   "metadata": {
    "tags": []
   },
   "source": [
    "You could find the model path in S3 from above logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54873d2f-2b86-41f9-ae2d-f71693d92cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
